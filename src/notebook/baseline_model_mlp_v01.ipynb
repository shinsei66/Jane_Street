{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "print(torch.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "%matplotlib inline\n",
    "from janest_model import MLPNet , CustomDataset, train_model\n",
    "from utils import PurgedGroupTimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile test.py\n",
    "#print('hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "USE_FINETUNE = True     \n",
    "FOLDS = 5\n",
    "GROUP_GAP = 20\n",
    "SEED = 66\n",
    "INPUTPATH = '../../input'\n",
    "NUM_EPOCH = 500\n",
    "BATCH_SIZE = 16384\n",
    "PATIANCE = 15\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "MDL_PATH  = '../models'\n",
    "MDL_NAME = 'mlp'\n",
    "NUM_LYR = 5\n",
    "VER = 'cv_base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_parquet(f'{INPUTPATH}/train.parquet')\n",
    "test_df = pd.read_csv(f'{INPUTPATH}/example_test.csv')\n",
    "pred_df  = pd.read_csv(f'{INPUTPATH}/example_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = train.query('date > 85').reset_index(drop = True) \n",
    "print(train.shape)\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "train['action'] =  \\\n",
    "(  (train['resp_1'] > 0.00001 ) & \\\n",
    "   (train['resp_2'] > 0.00001 ) & \\\n",
    "   (train['resp_3'] > 0.00001 ) & \\\n",
    "   (train['resp_4'] > 0.00001 ) & \\\n",
    "   (train['resp'] > 0.00001 )   ).astype('int')\n",
    "\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "\n",
    "X = train[features].values\n",
    "y = np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T\n",
    "#X = cp.array(train[features].values)\n",
    "#y = cp.array(np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T) #Multitarget\n",
    "#f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "f_mean = np.load( f'{INPUTPATH}/f_mean.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#np.save( f'{INPUTPATH}/f_mean.npy',f_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape[-1])\n",
    "print(y.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPNet(input_size = X.shape[-1], output_size = y.shape[-1]).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "sts = time.time()\n",
    "learn_hist_list = []\n",
    "save_path_list = []\n",
    "for fold, (tr, vl) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n",
    "    print('Fold : {}'.format(fold+1))\n",
    "    \n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    loaders = {'train':trn_loader, 'valid': val_loader}\n",
    "    trained_model, learn_hist, save_path =\\\n",
    "        train_model(model, criterion, optimizer, loaders, DEVICE, NUM_EPOCH, PATIANCE, \\\n",
    "                MDL_PATH, MDL_NAME, VER, fold+1)\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    plt.plot(learn_hist.epoch, learn_hist.valid_bce_loss, color = 'blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    plt.plot(learn_hist.epoch, learn_hist.train_bce_loss, color = 'red')\n",
    "    ax1.set_ylabel('Valid BCE Loss')\n",
    "    ax2.set_ylabel('Train BCE Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.show()\n",
    "    learn_hist['Fold'] = fold+1\n",
    "    learn_hist_list.append(learn_hist)\n",
    "    save_path_list.append(save_path)\n",
    "all_hist = pd.concat(learn_hist_list, axis=0)\n",
    "all_hist.reset_index(inplace=True, drop=True)\n",
    "all_hist.to_csv(f'{MDL_PATH}/{MDL_NAME}_{VER}/{MDL_NAME}_learning_history.csv', index=False)\n",
    "ed = time.time()\n",
    "print('Training process takes {:.2f} min.'.format((ed-sts)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath = True)\n",
    "def utility_score_numba(date, weight, resp, action):\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n",
    "    u = min(max(t, 0), 6) * np.sum(Pi)\n",
    "    return u\n",
    "\n",
    "#https://www.kaggle.com/gogo827jz/jane-street-super-fast-utility-score-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0\n",
    "loop = int(np.round(len(X)/BATCH_SIZE))\n",
    "pred_all = np.array([])\n",
    "for n in tqdm(range(loop)):\n",
    "    x_tt = X[BATCH_SIZE*n:BATCH_SIZE*(n+1),:]\n",
    "    if np.isnan(x_tt[:, 1:].sum()):\n",
    "        x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "    pred = 0.0\n",
    "    X_test = torch.FloatTensor(x_tt).to(DEVICE)\n",
    "    pred= model(X_test).cpu().detach().numpy()\n",
    "    if len(pred_all) == 0:\n",
    "        pred_all = pred.copy()\n",
    "    else:\n",
    "        pred_all = np.vstack([pred_all, pred]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = train['date'].values\n",
    "weight = train['weight'].values\n",
    "resp = train['resp'].values\n",
    "train['action'] = (train['resp'] > 0).astype('int')\n",
    "action_ans = train['action'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=0.5\n",
    "action = np.where(pred_all[:,0] >= th, 1, 0).astype(int).copy()\n",
    "utility_score_numba(date, weight, resp, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_score_numba(date, weight, resp, action_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{MDL_PATH}/{MDL_NAME}_{VER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets init -p ../models/autoencoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../models/mlp_base/dataset-metadata.json\n",
    "{\n",
    "    \"title\": \"Jane-Street\",\n",
    "    \"id\": \"shinsei66/Jane-Street\",\n",
    "    \"subtitle\": \"\",\n",
    "    \"description\": \"\",\n",
    "    \"isPrivate\": true,\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"unknown\" \n",
    "        }\n",
    "    ],\n",
    "    \"keywords\": [],\n",
    "    \"collaborators\": [],\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_99.pth\",\n",
    "            \"totalBytes\": 848,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_254.pth\",\n",
    "            \"totalBytes\": 856,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"mlp_base_984.pth\",\n",
    "            \"totalBytes\": 1316,\n",
    "            \"columns\": []\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets create -p  ../models/autoencoder_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du ../models/mlp_base/mlp_984.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets version -p  ../models/mlp_base -m \"mlp base 984 epoch\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.588px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 633.991364,
   "position": {
    "height": "40px",
    "left": "1283.99px",
    "right": "20px",
    "top": "120px",
    "width": "341.989px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
