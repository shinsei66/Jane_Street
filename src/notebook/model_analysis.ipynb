{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#import cupy as cp\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "print(torch.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "%matplotlib inline\n",
    "from janest_model import CustomDataset, train_model, autoencoder2, ResNetModel, SmoothBCEwLogits, utility_score_bincount, train_model_unity\n",
    "from janest_model import TransformerModel\n",
    "from utils import PurgedGroupTimeSeriesSplit, get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile test.py\n",
    "#print('hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "TRAINING = False\n",
    "USE_FINETUNE = True     \n",
    "FOLDS = 5\n",
    "GROUP_GAP = 20\n",
    "SEED = 66\n",
    "INPUTPATH = '../../input'\n",
    "NUM_EPOCH = 500\n",
    "BATCH_SIZE = 32768\n",
    "PATIANCE = 15\n",
    "LR = 0.0001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "MDL_PATH  = '../models'\n",
    "MDL_NAME = 'autoencoder'\n",
    "VER = 'early_stopping'\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1571415, 139)\n",
      "CPU times: user 10.3 s, sys: 4.73 s, total: 15 s\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_parquet(f'{INPUTPATH}/train.parquet')\n",
    "train = train.query('date > 85').reset_index(drop = True) \n",
    "print(train.shape)\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "train['action'] =  \\\n",
    "(  (train['resp_1'] > 0.00001 ) & \\\n",
    "   (train['resp_2'] > 0.00001 ) & \\\n",
    "   (train['resp_3'] > 0.00001 ) & \\\n",
    "   (train['resp_4'] > 0.00001 ) & \\\n",
    "   (train['resp'] > 0.00001 )   ).astype('int')\n",
    "\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "\n",
    "X = train[features].values\n",
    "y = np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "#f_mean = np.load( f'{INPUTPATH}/f_mean.npy')\n",
    "date = np.load( f'{INPUTPATH}/date.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp.npy')\n",
    "test_df = pd.read_csv(f'{INPUTPATH}/example_test.csv')\n",
    "pred_df  = pd.read_csv(f'{INPUTPATH}/example_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[-1])\n",
    "print(y.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    '''\n",
    "    >> model = \n",
    "        autoencoder(input_size = X.shape[-1], output_size = y.shape[-1],\\\n",
    "        noise = 0.1).to(DEVICE)\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(autoencoder, self).__init__()\n",
    "        input_size = kwargs['input_size']\n",
    "        output_size = kwargs['output_size']\n",
    "        noise = kwargs['noise']\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            #GaussianNoise(noise),\n",
    "            nn.Linear(input_size, 640),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(640, input_size)\n",
    "        )\n",
    "        self.hidden = nn.Linear(input_size, 320)\n",
    "        self.bat = nn.BatchNorm1d(320)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.hidden2 = nn.Linear(320, output_size)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.bat(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING:   \n",
    "    gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "    for fold, (tr, vl) in enumerate(gkf.split(y, y, date)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder_early_stopping/autoencoder_254.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder(input_size = X.shape[-1], output_size = y.shape[-1], noise=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=130, out_features=640, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=640, out_features=130, bias=True)\n",
       "  )\n",
       "  (hidden): Linear(in_features=130, out_features=320, bias=True)\n",
       "  (bat): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (hidden2): Linear(in_features=320, out_features=5, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../models/autoencoder_early_stopping/autoencoder_254.pth']\n"
     ]
    }
   ],
   "source": [
    "model_list  = glob.glob(f'{MDL_PATH}/{MDL_NAME}_{VER}/*.pth')\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6d9c900e3748218447771b2a155e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 10786.6377949325, return ration is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a3f0aebafa4ea589a181151f2a735a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 14589.84571618053, return ration is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c519cb6c6fa44198e8517a622dcb8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 13971.761285746, return ration is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78e4f40ca434f5abce22fdc9dfcae25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 13014.414197417686, return ration is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfc34d758c043ce88ed687879b2d1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 14679.412120092362, return ration is -0.0 \n"
     ]
    }
   ],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "for fold, (tr, vl) in enumerate(gkf.split(y,y, date)):\n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []   \n",
    "\n",
    "    for i, data in tqdm(enumerate(val_loader)):\n",
    "        x = data['x'].to(DEVICE)\n",
    "        outputs = np.zeros((len(x), 5))\n",
    "        with torch.no_grad():\n",
    "            for mdl in model_list:\n",
    "\n",
    "                model.eval()\n",
    "                outputs += model(x).sigmoid().detach().cpu().numpy()/len(model_list)\n",
    "            preds.append(outputs)\n",
    "\n",
    "    pred_all  = np.concatenate(preds)\n",
    "\n",
    "\n",
    "#             action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "    action = np.where(np.mean(pred_all, axis=1)> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    if np.sum(action)>0:\n",
    "        date_vl = date[vl].copy()\n",
    "        weight_vl = weight[vl].copy()\n",
    "        resp_vl = resp[vl].copy()\n",
    "        action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "        cv_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action)\n",
    "        max_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "        print('CV score is {}, Max score is {}, return ration is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "#         logger.info('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "    else:\n",
    "        raise ZeroDivisionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder_ho_base_007/autoencoder_fold_ho_19.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = np.load( f'{INPUTPATH}/f_mean_03.npy')\n",
    "X = np.load( f'{INPUTPATH}/X_03.npy')\n",
    "y = np.load( f'{INPUTPATH}/y_03.npy')\n",
    "date = np.load( f'{INPUTPATH}/date_03.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight_03.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp_03.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder2(input_size = X.shape[-1], output_size = y.shape[-1], noise=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder2(\n",
       "  (hidden): Linear(in_features=316, out_features=640, bias=True)\n",
       "  (bat): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (hidden2): Linear(in_features=640, out_features=5, bias=True)\n",
       "  (act): Sigmoid()\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=158, out_features=640, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=640, out_features=158, bias=True)\n",
       "  )\n",
       "  (layer): Sequential(\n",
       "    (0): Linear(in_features=316, out_features=640, bias=True)\n",
       "    (1): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=640, out_features=320, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=320, out_features=640, bias=True)\n",
       "    (6): Linear(in_features=640, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../models/autoencoder_ho_base_007/autoencoder_fold_ho_19.pth']\n"
     ]
    }
   ],
   "source": [
    "MDL_NAME = 'autoencoder'\n",
    "VER = 'ho_base_007'\n",
    "model_list  = glob.glob(f'{MDL_PATH}/{MDL_NAME}_{VER}/*.pth')\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e281ea078644748d4db660a82138e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuqing/Jane_Street/src/notebook/janest_model.py:326: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is nan, return ration is nan \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdbbfe374e34981877e53608c508ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is nan, return ration is nan \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417601bbaf454985b117a55c50e1a57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is nan, return ration is nan \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff37c11f53e4058be492bc3b9c40636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is nan, return ration is nan \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944987f6027248c6abc268441fd4e2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is nan, return ration is nan \n"
     ]
    }
   ],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "for fold, (tr, vl) in enumerate(gkf.split(y,y, date)):\n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []   \n",
    "\n",
    "    for i, data in tqdm(enumerate(val_loader)):\n",
    "        x = data['x'].to(DEVICE)\n",
    "        outputs = np.zeros((len(x), 5))\n",
    "        with torch.no_grad():\n",
    "            for mdl in model_list:\n",
    "\n",
    "                model.eval()\n",
    "                outputs += model(x).sigmoid().detach().cpu().numpy()/len(model_list)\n",
    "            preds.append(outputs)\n",
    "\n",
    "    pred_all  = np.concatenate(preds)\n",
    "\n",
    "\n",
    "#             action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "    action = np.where(np.mean(pred_all, axis=1)> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    if np.sum(action)>0:\n",
    "        date_vl = date[vl].copy()\n",
    "        weight_vl = weight[vl].copy()\n",
    "        resp_vl = resp[vl].copy()\n",
    "        action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "        cv_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action)\n",
    "        max_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "        print('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "#         logger.info('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "    else:\n",
    "        raise ZeroDivisionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoencoder_cv_base_009 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =glob.glob('../models/autoencoder_cv_base_009/*.pth')\n",
    "model_list = [\n",
    " '../models/autoencoder_cv_base_009/autoencoder_fold_1_5.pth',\n",
    "'../models/autoencoder_cv_base_009/autoencoder_fold_2_4.pth',\n",
    "    '../models/autoencoder_cv_base_009/autoencoder_fold_3_2.pth',\n",
    "     '../models/autoencoder_cv_base_009/autoencoder_fold_4_28.pth',\n",
    " '../models/autoencoder_cv_base_009/autoencoder_fold_5_28.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " f_mean = np.load( f'{INPUTPATH}/f_mean.npy')\n",
    "X = np.load( f'{INPUTPATH}/X.npy')\n",
    "y = np.load( f'{INPUTPATH}/y.npy')\n",
    "date = np.load( f'{INPUTPATH}/date.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder2(input_size = X.shape[-1], output_size = y.shape[-1], noise=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5b006dedcb45738c115e100d27047b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 106.910353088892, Max score is 10786.33238504988, return ratio is 1.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bbc6b3e91c4140ae57dfc23d8f2883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 14589.539114302985, return ratio is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af3f397d1d1492fbfe2202a393b9ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 53.68795754969435, Max score is 13972.055056022891, return ratio is 0.4 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d19f5092e1b478fb65e98267d605972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is -0.0, Max score is 13014.211417401355, return ratio is -0.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1019afa6784fd197d7c2ef10a3fe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 10.44953018179509, Max score is 14679.813965730122, return ratio is 0.1 \n"
     ]
    }
   ],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "oof = np.zeros(len(X))\n",
    "for fold, (tr, vl) in enumerate(gkf.split(y,y, date)):\n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []   \n",
    "\n",
    "    for i, data in tqdm(enumerate(val_loader)):\n",
    "        x = data['x'].to(DEVICE)\n",
    "        outputs = np.zeros((len(x), y.shape[1]))\n",
    "        with torch.no_grad():\n",
    "            for mdl in model_list[fold]:\n",
    "\n",
    "                model.eval()\n",
    "                outputs = model(x).sigmoid().detach().cpu().numpy()\n",
    "            preds.append(outputs)\n",
    "\n",
    "    pred_all  = np.concatenate(preds)\n",
    "\n",
    "\n",
    "#             action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "    action = np.where(np.mean(pred_all, axis=1)> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    oof[vl] = action\n",
    "    if np.sum(action)>0:\n",
    "        date_vl = date[vl].copy()\n",
    "        weight_vl = weight[vl].copy()\n",
    "        resp_vl = resp[vl].copy()\n",
    "        action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "        cv_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action)\n",
    "        max_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "        print('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "#         logger.info('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "    else:\n",
    "        raise ZeroDivisionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76485.72989706146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(utility_score_bincount(date , weight , resp, y[:,0]  ))\n",
    "print(utility_score_bincount(date , weight , resp, y[:,0]  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter( np.mean(pred_all, axis=1), action_ans_vl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "model_list =glob.glob('../models/public/*.pth')\n",
    "model_list = [\n",
    "    '../models/public/online_model0.pth',\n",
    " '../models/public/online_model1.pth',\n",
    "    '../models/public/online_model2.pth',\n",
    "     '../models/public/online_model3.pth',\n",
    " '../models/public/online_model4.pth',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n",
    "        self.dropout0 = nn.Dropout(0.2)\n",
    "\n",
    "        dropout_rate = 0.2\n",
    "        hidden_size = 256\n",
    "        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n",
    "\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "        self.PReLU = nn.PReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        # self.GeLU = nn.GELU()\n",
    "        self.RReLU = nn.RReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x1 = self.dense1(x)\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x1 = self.LeakyReLU(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "\n",
    "        x = torch.cat([x, x1], 1)\n",
    "\n",
    "        x2 = self.dense2(x)\n",
    "        x2 = self.batch_norm2(x2)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x2 = self.LeakyReLU(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "\n",
    "        x3 = self.dense3(x)\n",
    "        x3 = self.batch_norm3(x3)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x3 = self.LeakyReLU(x3)\n",
    "        x3 = self.dropout3(x3)\n",
    "\n",
    "        x = torch.cat([x2, x3], 1)\n",
    "\n",
    "        x4 = self.dense4(x)\n",
    "        x4 = self.batch_norm4(x4)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x4 = self.LeakyReLU(x4)\n",
    "        x4 = self.dropout4(x4)\n",
    "\n",
    "        x = torch.cat([x3, x4], 1)\n",
    "\n",
    "        x = self.dense5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Filling...\n",
      "Converting...\n",
      "Finish.\n"
     ]
    }
   ],
   "source": [
    "print('Loading...')\n",
    "train = pd.read_parquet(f'{INPUTPATH}/train.parquet')\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "print('Filling...')\n",
    "f_mean = train[features[1:]].mean()\n",
    "train = train.loc[train.weight > 0].reset_index(drop = True)\n",
    "train[features[1:]] = train[features[1:]].fillna(f_mean)\n",
    "# train['action'] = (train['resp'] > 0).astype('int')\n",
    "\n",
    "\n",
    "print('Converting...')\n",
    "# train = train.to_pandas()\n",
    "f_mean = f_mean.values#.get()\n",
    "# np.save('f_mean.npy', f_mean)\n",
    "\n",
    "x_tt = train.loc[:, features].values\n",
    "train['features_41_42_43'] = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n",
    "train['features_1_2'] = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "all_feat_cols = features #[col for col in feat_cols]\n",
    "\n",
    "\n",
    "date = train.date.values\n",
    "weight = train.weight.values\n",
    "resp = train.resp.values\n",
    "X = train[features].values\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n",
    "\n",
    "\n",
    "print('Finish.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1571415, 132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = resp_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (batch_norm0): BatchNorm1d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout0): Dropout(p=0.2, inplace=False)\n",
       "  (dense1): Linear(in_features=132, out_features=256, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dense2): Linear(in_features=388, out_features=256, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (dense3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (dense4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (batch_norm4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout4): Dropout(p=0.2, inplace=False)\n",
       "  (dense5): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (Relu): ReLU(inplace=True)\n",
       "  (PReLU): PReLU(num_parameters=1)\n",
       "  (LeakyReLU): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  (RReLU): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457352b079e4443b985d023c2332a164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n",
      "(16384, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7828,5) (7168,5) (7828,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-715c39afa389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7828,5) (7168,5) (7828,5) "
     ]
    }
   ],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "for fold, (tr, vl) in enumerate(gkf.split(y,y, date)):\n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []   \n",
    "\n",
    "    for i, data in tqdm(enumerate(val_loader)):\n",
    "        x = data['x'].to(DEVICE)\n",
    "        outputs = np.zeros((len(x), y.shape[1]))\n",
    "        with torch.no_grad():\n",
    "            for mdl in model_list:\n",
    "                model.load_state_dict(torch.load(mdl))\n",
    "                model.eval()\n",
    "                \n",
    "                outputs += model(x).sigmoid().detach().cpu().numpy()/len(model_list)\n",
    "                print(outputs.shape)\n",
    "            preds.append(outputs)\n",
    "\n",
    "    pred_all  = np.concatenate(preds)\n",
    "\n",
    "#             action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "    action = np.where(np.mean(pred_all, axis=1)> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    if np.sum(action)>0:\n",
    "        date_vl = date[vl].copy()\n",
    "        weight_vl = weight[vl].copy()\n",
    "        resp_vl = resp[vl].copy()\n",
    "        action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "        cv_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action)\n",
    "        max_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "        print('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "#         logger.info('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "    else:\n",
    "        raise ZeroDivisionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAVER = '05'\n",
    "# SERIES= 1024\n",
    "f_mean = np.load( f'{INPUTPATH}/f_mean_{DATAVER}.npy')\n",
    "X = np.load( f'{INPUTPATH}/X_{DATAVER}.npy')\n",
    "y = np.load( f'{INPUTPATH}/y_{DATAVER}.npy')\n",
    "date = np.load( f'{INPUTPATH}/date_{DATAVER}.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight_{DATAVER}.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp_{DATAVER}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/transformer_cv_base_003/transformer_fold_2_35.pth',\n",
       " '../models/transformer_cv_base_003/transformer_fold_1_5.pth',\n",
       " '../models/transformer_cv_base_003/transformer_fold_3_6.pth',\n",
       " '../models/transformer_cv_base_003/transformer_fold_4_8.pth',\n",
       " '../models/transformer_cv_base_003/transformer_fold_5_7.pth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "model_list =glob.glob('../models/transformer_cv_base_003/*.pth')\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    " '../models/transformer_cv_base_003/transformer_fold_1_5.pth',\n",
    "'../models/transformer_cv_base_003/transformer_fold_2_35.pth',\n",
    " '../models/transformer_cv_base_003/transformer_fold_3_6.pth',\n",
    " '../models/transformer_cv_base_003/transformer_fold_4_8.pth',\n",
    " '../models/transformer_cv_base_003/transformer_fold_5_7.pth'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (layer0): Sequential(\n",
       "    (0): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=160, out_features=512, bias=True)\n",
       "    (2): Swish_module()\n",
       "  )\n",
       "  (layer1): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(input_size = X.shape[-1], output_size = y.shape[-1], batch_size = BATCH_SIZE).to(DEVICE)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312613, 160)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7052ae154ee4431abba84f3a88cc89a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 3223.485028294815, Max score is 10786.33238504988, return ratio is 29.9 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d81cbbc5a34f9cb6b692a164cb4801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 620.4919984921067, Max score is 14589.539114302985, return ratio is 4.3 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d09620f8114a55ae7dcf9b07936417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 1061.0141499154147, Max score is 13972.055056022891, return ratio is 7.6 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5810b6588364d2ca01730ad41285544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 199.75335967892272, Max score is 13014.211417401355, return ratio is 1.5 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c2fab2fdef45d88296e5aadd25f9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 1479.8201565792601, Max score is 14679.813965730122, return ratio is 10.1 \n"
     ]
    }
   ],
   "source": [
    "gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "for fold, (tr, vl) in enumerate(gkf.split(y,y, date)):\n",
    "    X_tr, X_val = X[tr], X[vl]\n",
    "    y_tr, y_val = y[tr], y[vl]\n",
    "    trn_dat = CustomDataset(X_tr, y_tr)\n",
    "    val_dat = CustomDataset(X_val, y_val)\n",
    "    trn_loader = DataLoader(trn_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dat , batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []   \n",
    "\n",
    "    for i, data in tqdm(enumerate(val_loader)):\n",
    "        x = data['x'].to(DEVICE)\n",
    "        outputs = np.zeros((len(x), y.shape[1]))\n",
    "        with torch.no_grad():\n",
    "            for mdl in model_list:\n",
    "                model.load_state_dict(torch.load(mdl))\n",
    "                model.eval()\n",
    "                if len(x) != len(model(x)):\n",
    "                    x = x[:len(model(x))].clone()\n",
    "                outputs += model(x).sigmoid().detach().cpu().numpy()/len(model_list)\n",
    "                \n",
    "            preds.append(outputs)\n",
    "\n",
    "    pred_all  = np.concatenate(preds)\n",
    "\n",
    "    action = np.where(np.mean(pred_all, axis=1)> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    if np.sum(action)>0:\n",
    "        date_vl = date[vl].copy()\n",
    "        weight_vl = weight[vl].copy()\n",
    "        resp_vl = resp[vl].copy()\n",
    "        action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "        cv_score = utility_score_bincount(date_vl[:action.shape[0]]  , weight_vl[:action.shape[0]], resp_vl[:action.shape[0]]  , action)\n",
    "        max_score = utility_score_bincount(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "        print('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "#         logger.info('CV score is {}, Max score is {}, return ratio is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))\n",
    "    else:\n",
    "        raise ZeroDivisionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_list[1]))\n",
    "len(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7168, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x[:len(model(x))]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    " m = nn.Conv1d(160, 512, 1, stride=2)\n",
    "input = torch.randn(20, 160).unsqueeze(2)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 160, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.permute(2,0,1).squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/ae_cv_base\n"
     ]
    }
   ],
   "source": [
    "print(f'{MDL_PATH}/{MDL_NAME}_{VER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets init -p ../models/autoencoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../models/ae_cv_base/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/ae_cv_base/dataset-metadata.json\n",
    "{\n",
    "    \"title\": \"Jane-Street\",\n",
    "    \"id\": \"shinsei66/Jane-Street\",\n",
    "    \"subtitle\": \"\",\n",
    "    \"description\": \"\",\n",
    "    \"isPrivate\": true,\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"unknown\" \n",
    "        }\n",
    "    ],\n",
    "    \"keywords\": [],\n",
    "    \"collaborators\": [],\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_99.pth\",\n",
    "            \"totalBytes\": 848,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_254.pth\",\n",
    "            \"totalBytes\": 856,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"mlp_base_984.pth\",\n",
    "            \"totalBytes\": 1316,\n",
    "            \"columns\": []\n",
    "        },\n",
    "         {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_1_18.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_2_428.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_3_500.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_4_199.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_5_497.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets create -p  ../models/autoencoder_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\t../models/ae_cv_base/ae_fold_5_497.pth\r\n",
      "76\t../models/ae_cv_base/ae_learning_history.csv\r\n",
      "840\t../models/ae_cv_base/ae_fold_2_428.pth\r\n",
      "4\t../models/ae_cv_base/.ipynb_checkpoints\r\n",
      "840\t../models/ae_cv_base/ae_fold_3_500.pth\r\n",
      "840\t../models/ae_cv_base/ae_fold_4_199.pth\r\n",
      "840\t../models/ae_cv_base/ae_fold_1_18.pth\r\n",
      "4284\t../models/ae_cv_base/\r\n"
     ]
    }
   ],
   "source": [
    "!du ../models/ae_cv_base/ -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file ae_fold_5_497.pth\n",
      "100%|| 836k/836k [08:47<00:00, 1.62kB/s]\n",
      "Upload successful: ae_fold_5_497.pth (836KB)\n",
      "Starting upload for file ae_learning_history.csv\n",
      "100%|| 73.9k/73.9k [08:46<00:00, 144B/s]\n",
      "Upload successful: ae_learning_history.csv (74KB)\n",
      "Starting upload for file ae_fold_2_428.pth\n",
      "100%|| 836k/836k [08:47<00:00, 1.62kB/s]\n",
      "Upload successful: ae_fold_2_428.pth (836KB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file ae_fold_3_500.pth\n",
      "100%|| 836k/836k [08:46<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_3_500.pth (836KB)\n",
      "Starting upload for file ae_fold_4_199.pth\n",
      "100%|| 836k/836k [08:45<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_4_199.pth (836KB)\n",
      "Starting upload for file ae_fold_1_18.pth\n",
      "100%|| 836k/836k [08:46<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_1_18.pth (836KB)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/shinsei66/jane-street\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets version -p  ../models/ae_cv_base -m \"auto encoder 5 fold cv baseline\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.547px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 633.969,
   "position": {
    "height": "40px",
    "left": "1281.98px",
    "right": "20px",
    "top": "120px",
    "width": "341.969px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
