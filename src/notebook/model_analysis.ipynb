{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 11 18:10:21 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.27.04    Driver Version: 460.27.04    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    On   | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   57C    P8    32W / 350W |    325MiB / 24268MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1257      G   /usr/lib/xorg/Xorg                 45MiB |\r\n",
      "|    0   N/A  N/A      1897      G   /usr/lib/xorg/Xorg                117MiB |\r\n",
      "|    0   N/A  N/A      2085      G   /usr/bin/gnome-shell               27MiB |\r\n",
      "|    0   N/A  N/A      4846      G   ...AAAAAAAA== --shared-files      114MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#import cupy as cp\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "print(torch.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "%matplotlib inline\n",
    "from janest_model import MLPNet , CustomDataset, train_model, autoencoder2\n",
    "from utils import PurgedGroupTimeSeriesSplit, get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile test.py\n",
    "#print('hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "TRAINING = False\n",
    "USE_FINETUNE = True     \n",
    "FOLDS = 5\n",
    "GROUP_GAP = 20\n",
    "SEED = 66\n",
    "INPUTPATH = '../../input'\n",
    "NUM_EPOCH = 500\n",
    "BATCH_SIZE = 16384\n",
    "PATIANCE = 15\n",
    "LR = 0.0001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "MDL_PATH  = '../models'\n",
    "MDL_NAME = 'autoencoder'\n",
    "VER = 'early_stopping'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1571415, 139)\n",
      "CPU times: user 9.97 s, sys: 5.06 s, total: 15 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_parquet(f'{INPUTPATH}/train.parquet')\n",
    "train = train.query('date > 85').reset_index(drop = True) \n",
    "print(train.shape)\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "train['action'] =  \\\n",
    "(  (train['resp_1'] > 0.00001 ) & \\\n",
    "   (train['resp_2'] > 0.00001 ) & \\\n",
    "   (train['resp_3'] > 0.00001 ) & \\\n",
    "   (train['resp_4'] > 0.00001 ) & \\\n",
    "   (train['resp'] > 0.00001 )   ).astype('int')\n",
    "\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "\n",
    "X = train[features].values\n",
    "y = np.stack([(train[c] > 0.000001).astype('int') for c in resp_cols]).T\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "#f_mean = np.load( f'{INPUTPATH}/f_mean.npy')\n",
    "date = np.load( f'{INPUTPATH}/date.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp.npy')\n",
    "test_df = pd.read_csv(f'{INPUTPATH}/example_test.csv')\n",
    "pred_df  = pd.read_csv(f'{INPUTPATH}/example_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[-1])\n",
    "print(y.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    '''\n",
    "    >> model = \n",
    "        autoencoder(input_size = X.shape[-1], output_size = y.shape[-1],\\\n",
    "        noise = 0.1).to(DEVICE)\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(autoencoder, self).__init__()\n",
    "        input_size = kwargs['input_size']\n",
    "        output_size = kwargs['output_size']\n",
    "        noise = kwargs['noise']\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            #GaussianNoise(noise),\n",
    "            nn.Linear(input_size, 640),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(640, input_size)\n",
    "        )\n",
    "        self.hidden = nn.Linear(input_size, 320)\n",
    "        self.bat = nn.BatchNorm1d(320)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.hidden2 = nn.Linear(320, output_size)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.bat(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING:   \n",
    "    gkf =  PurgedGroupTimeSeriesSplit(n_splits = FOLDS,  group_gap = GROUP_GAP)\n",
    "    for fold, (tr, vl) in enumerate(gkf.split(y, y, date)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder(input_size = X.shape[-1], output_size = y.shape[-1], noise=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=130, out_features=640, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=640, out_features=130, bias=True)\n",
       "  )\n",
       "  (hidden): Linear(in_features=130, out_features=320, bias=True)\n",
       "  (bat): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (hidden2): Linear(in_features=320, out_features=5, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../models/autoencoder_early_stopping/autoencoder_254.pth']\n"
     ]
    }
   ],
   "source": [
    "model_list  = glob.glob(f'{MDL_PATH}/{MDL_NAME}_{VER}/*.pth')\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath = True)\n",
    "def utility_score_numba(date, weight, resp, action):\n",
    "    Pi = np.bincount(date, weight * resp * action)\n",
    "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / len(Pi))\n",
    "    u = min(max(t, 0), 6) * np.sum(Pi)\n",
    "    return u\n",
    "\n",
    "#https://www.kaggle.com/gogo827jz/jane-street-super-fast-utility-score-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312613"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312613"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311296"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311296"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 2858.543108529276, Max score is 12894.874005197811, return ration is 22.2 \n"
     ]
    }
   ],
   "source": [
    "loop = int(np.round(len(X[vl])/BATCH_SIZE))\n",
    "pred_all = np.array([])\n",
    "x_tt = X[vl].copy()\n",
    "#x_tt = x_t[BATCH_SIZE*n:BATCH_SIZE*(n+1),:]\n",
    "if np.isnan(x_tt[:, 1:].sum()):\n",
    "    x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "pred = 0.0\n",
    "X_test = torch.FloatTensor(x_tt).to(DEVICE)\n",
    "for mdl in model_list:\n",
    "    load_weights = torch.load(mdl)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model.eval()\n",
    "    pred += model(X_test).cpu().detach().numpy() \n",
    "if len(pred_all) == 0:\n",
    "    pred_all = pred.copy()\n",
    "else:\n",
    "    pred_all = np.vstack([pred_all, pred]).copy()\n",
    "\n",
    "action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "if np.sum(action)>0:\n",
    "    date_vl = date[vl].copy()\n",
    "    weight_vl = weight[vl].copy()\n",
    "    resp_vl = resp[vl].copy()\n",
    "    action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    cv_score = utility_score_numba(date_vl , weight_vl , resp_vl , action)\n",
    "    max_score = utility_score_numba(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "    print('CV score is {}, Max score is {}, return ration is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = np.load( f'{INPUTPATH}/f_mean.npy')\n",
    "X = np.load( f'{INPUTPATH}/X.npy')\n",
    "y = np.load( f'{INPUTPATH}/y.npy')\n",
    "date = np.load( f'{INPUTPATH}/date.npy')\n",
    "weight = np.load( f'{INPUTPATH}/weight.npy' )\n",
    "resp = np.load( f'{INPUTPATH}/resp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder2(input_size = X.shape[-1], output_size = y.shape[-1], noise=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder2(\n",
       "  (hidden): Linear(in_features=316, out_features=640, bias=True)\n",
       "  (bat): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (hidden2): Linear(in_features=640, out_features=5, bias=True)\n",
       "  (act): Sigmoid()\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=158, out_features=640, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=640, out_features=158, bias=True)\n",
       "  )\n",
       "  (layer): Sequential(\n",
       "    (0): Linear(in_features=316, out_features=640, bias=True)\n",
       "    (1): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=640, out_features=320, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=320, out_features=640, bias=True)\n",
       "    (6): Linear(in_features=640, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../models/autoencoder_ho_base_007/autoencoder_fold_ho_19.pth']\n"
     ]
    }
   ],
   "source": [
    "MDL_NAME = 'autoencoder'\n",
    "VER = 'ho_base_007'\n",
    "model_list  = glob.glob(f'{MDL_PATH}/{MDL_NAME}_{VER}/*.pth')\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 504.43170307177337, Max score is 12893.32054803533, return ration is 3.9 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "THRESHOLD = 0\n",
    "loop = int(np.round(len(X[vl])/BATCH_SIZE))\n",
    "pred_all = np.array([])\n",
    "x_tt = X[vl].copy()\n",
    "#x_tt = x_t[BATCH_SIZE*n:BATCH_SIZE*(n+1),:]\n",
    "if np.isnan(x_tt[:, 1:].sum()):\n",
    "    x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "pred = 0.0\n",
    "X_test = torch.FloatTensor(x_tt).to(DEVICE)\n",
    "for mdl in model_list:\n",
    "    load_weights = torch.load(mdl)\n",
    "    model.load_state_dict(load_weights)\n",
    "    model.eval()\n",
    "    pred += model(X_test).cpu().detach().numpy() \n",
    "if len(pred_all) == 0:\n",
    "    pred_all = pred.copy()\n",
    "else:\n",
    "    pred_all = np.vstack([pred_all, pred]).copy()\n",
    "\n",
    "action = np.where(pred_all[:,0] >= THRESHOLD, 1, 0).astype(int).copy()\n",
    "if np.sum(action)>0:\n",
    "    date_vl = date[vl].copy()\n",
    "    weight_vl = weight[vl].copy()\n",
    "    resp_vl = resp[vl].copy()\n",
    "    action_ans_vl = np.where(y[vl,0]> THRESHOLD, 1, 0).astype(int).copy()\n",
    "    cv_score = utility_score_numba(date_vl , weight_vl , resp_vl , action)\n",
    "    max_score = utility_score_numba(date_vl , weight_vl , resp_vl , action_ans_vl )\n",
    "    print('CV score is {}, Max score is {}, return ration is {:.1f} '.format(cv_score, max_score, 100*(cv_score/max_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = train['date'].values\n",
    "weight = train['weight'].values\n",
    "resp = train['resp'].values\n",
    "train['action'] = (train['resp'] > 0).astype('int')\n",
    "action_ans = train['action'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3666.890810146739"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th=0.5\n",
    "action = np.where(pred_all[:,0] >= th, 1, 0).astype(int).copy()\n",
    "utility_score_numba(date, weight, resp, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173797.76047460194"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_score_numba(date, weight, resp, action_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17884"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/ae_cv_base\n"
     ]
    }
   ],
   "source": [
    "print(f'{MDL_PATH}/{MDL_NAME}_{VER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets init -p ../models/autoencoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../models/ae_cv_base/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/ae_cv_base/dataset-metadata.json\n",
    "{\n",
    "    \"title\": \"Jane-Street\",\n",
    "    \"id\": \"shinsei66/Jane-Street\",\n",
    "    \"subtitle\": \"\",\n",
    "    \"description\": \"\",\n",
    "    \"isPrivate\": true,\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"name\": \"unknown\" \n",
    "        }\n",
    "    ],\n",
    "    \"keywords\": [],\n",
    "    \"collaborators\": [],\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_99.pth\",\n",
    "            \"totalBytes\": 848,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"autoencoder_254.pth\",\n",
    "            \"totalBytes\": 856,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"mlp_base_984.pth\",\n",
    "            \"totalBytes\": 1316,\n",
    "            \"columns\": []\n",
    "        },\n",
    "         {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_1_18.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_2_428.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_3_500.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_4_199.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        },\n",
    "        {\n",
    "            \"description\": null,\n",
    "            \"name\": \"ae_fold_5_497.pth\",\n",
    "            \"totalBytes\": 840,\n",
    "            \"columns\": []\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets create -p  ../models/autoencoder_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\t../models/ae_cv_base/ae_fold_5_497.pth\r\n",
      "76\t../models/ae_cv_base/ae_learning_history.csv\r\n",
      "840\t../models/ae_cv_base/ae_fold_2_428.pth\r\n",
      "4\t../models/ae_cv_base/.ipynb_checkpoints\r\n",
      "840\t../models/ae_cv_base/ae_fold_3_500.pth\r\n",
      "840\t../models/ae_cv_base/ae_fold_4_199.pth\r\n",
      "840\t../models/ae_cv_base/ae_fold_1_18.pth\r\n",
      "4284\t../models/ae_cv_base/\r\n"
     ]
    }
   ],
   "source": [
    "!du ../models/ae_cv_base/ -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file ae_fold_5_497.pth\n",
      "100%|████████████████████████████████████████| 836k/836k [08:47<00:00, 1.62kB/s]\n",
      "Upload successful: ae_fold_5_497.pth (836KB)\n",
      "Starting upload for file ae_learning_history.csv\n",
      "100%|████████████████████████████████████████| 73.9k/73.9k [08:46<00:00, 144B/s]\n",
      "Upload successful: ae_learning_history.csv (74KB)\n",
      "Starting upload for file ae_fold_2_428.pth\n",
      "100%|████████████████████████████████████████| 836k/836k [08:47<00:00, 1.62kB/s]\n",
      "Upload successful: ae_fold_2_428.pth (836KB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file ae_fold_3_500.pth\n",
      "100%|████████████████████████████████████████| 836k/836k [08:46<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_3_500.pth (836KB)\n",
      "Starting upload for file ae_fold_4_199.pth\n",
      "100%|████████████████████████████████████████| 836k/836k [08:45<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_4_199.pth (836KB)\n",
      "Starting upload for file ae_fold_1_18.pth\n",
      "100%|████████████████████████████████████████| 836k/836k [08:46<00:00, 1.63kB/s]\n",
      "Upload successful: ae_fold_1_18.pth (836KB)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/shinsei66/jane-street\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets version -p  ../models/ae_cv_base -m \"auto encoder 5 fold cv baseline\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.562px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 633.991364,
   "position": {
    "height": "40px",
    "left": "1283.99px",
    "right": "20px",
    "top": "120px",
    "width": "341.989px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
